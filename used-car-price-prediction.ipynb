{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load data from multiple Excel files\n",
    "cities = ['bangalore', 'chennai', 'delhi', 'hyderabad', 'jaipur', 'kolkata']\n",
    "dfs = []\n",
    "\n",
    "for city in cities:\n",
    "    df = pd.read_excel(f\"C:\\\\Users\\\\surej\\\\OneDrive\\\\Desktop\\\\project\\\\cardekhoproject\\\\{city}_cars.xlsx\")\n",
    "    df['City'] = city.capitalize()\n",
    "    dfs.append(df)\n",
    "\n",
    "all_cars_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Improved data preprocessing for kilometers\n",
    "def clean_kilometers(km_str):\n",
    "    if isinstance(km_str, str):\n",
    "        km_str = km_str.replace(' kms', '').replace(',', '').strip()\n",
    "    return pd.to_numeric(km_str, errors='coerce')\n",
    "\n",
    "# Feature extraction functions\n",
    "def extract_engine_capacity(specs):\n",
    "    for section in specs.get('data', []):\n",
    "        if section.get('subHeading') == 'Engine':\n",
    "            for item in section.get('list', []):\n",
    "                if item.get('key') == 'Displacement':\n",
    "                    return item.get('value', '')\n",
    "    return '' \n",
    "\n",
    "def extract_year(make_year):\n",
    "    match = re.search(r'\\d{4}', make_year)\n",
    "    return match.group(0) if match else make_year\n",
    "\n",
    "def convert_price(price_str):\n",
    "    price_str = price_str.replace('â‚¹', '').replace(',', '').strip().lower()\n",
    "\n",
    "    if 'lakh' in price_str:\n",
    "        return float(re.findall(r'\\d+\\.?\\d*', price_str)[0]) * 1e5\n",
    "    elif 'crore' in price_str:\n",
    "        return float(re.findall(r'\\d+\\.?\\d*', price_str)[0]) * 1e7\n",
    "    else:\n",
    "        return float(re.findall(r'\\d+\\.?\\d*', price_str)[0])\n",
    "\n",
    "def extract_features(row):\n",
    "    new_car_detail = ast.literal_eval(row['new_car_detail'])\n",
    "    new_car_overview = ast.literal_eval(row['new_car_overview'])\n",
    "    new_car_specs = ast.literal_eval(row['new_car_specs'])\n",
    "\n",
    "    make_year = new_car_overview['top'][0].get('value', '') if new_car_overview.get('top') else ''\n",
    "\n",
    "    extracted_data = {\n",
    "        'fuel_type': new_car_detail.get('ft', ''),\n",
    "        'body_type': new_car_detail.get('bt', ''),\n",
    "        'kilometers': new_car_detail.get('km', '').replace(' kms', '').replace(',', ''),\n",
    "        'transmission': new_car_detail.get('transmission', ''),\n",
    "        'engine_capacity': extract_engine_capacity(new_car_specs),\n",
    "        'make_year': extract_year(make_year),\n",
    "        'owner_type': new_car_detail.get('ownerNo', 0),  \n",
    "        'price': convert_price(new_car_detail.get('price', ''))\n",
    "    }\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "structured_data = all_cars_df.apply(extract_features, axis=1, result_type='expand')\n",
    "structured_data['City'] = all_cars_df['City']\n",
    "\n",
    "# Handling missing values in make_year\n",
    "structured_data['make_year'] = pd.to_numeric(structured_data['make_year'], errors='coerce')\n",
    "default_year = structured_data['make_year'].median()  \n",
    "structured_data['make_year'].fillna(default_year, inplace=True)\n",
    "structured_data['make_year'] = structured_data['make_year'].astype(int)\n",
    "\n",
    "#print(structured_data.info()) \n",
    "#print(structured_data.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "#print(\"Missing values before handling:\")\n",
    "#print(structured_data.isnull().sum())\n",
    "\n",
    "structured_data['kilometers'] = structured_data['kilometers'].apply(clean_kilometers)\n",
    "\n",
    "# Handle missing values with KNN imputation\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "structured_data['kilometers'] = imputer.fit_transform(structured_data[['kilometers']])\n",
    "\n",
    "# Identify and cap outliers for kilometers using the 1.5*IQR rule\n",
    "Q1 = structured_data['kilometers'].quantile(0.25)\n",
    "Q3 = structured_data['kilometers'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "structured_data['kilometers'] = np.where(structured_data['kilometers'] > upper_bound, upper_bound, \n",
    "                                         np.where(structured_data['kilometers'] < lower_bound, lower_bound, structured_data['kilometers']))\n",
    "\n",
    "# Identify and cap outliers for price using the 1.5*IQR rule\n",
    "Q1_price = structured_data['price'].quantile(0.25)\n",
    "Q3_price = structured_data['price'].quantile(0.75)\n",
    "IQR_price = Q3_price - Q1_price\n",
    "lower_bound_price = Q1_price - 1.5 * IQR_price\n",
    "upper_bound_price = Q3_price + 1.5 * IQR_price\n",
    "\n",
    "structured_data['price'] = np.where(structured_data['price'] > upper_bound_price, upper_bound_price, \n",
    "                                    np.where(structured_data['price'] < lower_bound_price, lower_bound_price, structured_data['price']))\n",
    "\n",
    "# One-hot encoding\n",
    "#structured_data = pd.get_dummies(structured_data, columns=['City'], drop_first=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = structured_data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "\n",
    "for column in categorical_columns:\n",
    "    structured_data[column] = label_encoders[column].fit_transform(structured_data[column])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "structured_data[['kilometers', 'engine_capacity']] = scaler.fit_transform(structured_data[['kilometers', 'engine_capacity']])\n",
    "\n",
    "# Create additional features\n",
    "#structured_data['log_kilometers'] = np.log1p(structured_data['kilometers'])\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "# Descriptive Statistics\n",
    "#print(structured_data.describe())\n",
    "\n",
    "# Data Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(structured_data['price'], bins=30, kde=True)\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='price', data=structured_data)\n",
    "plt.title('Price Boxplot')\n",
    "plt.xlabel('Price')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_data = structured_data.select_dtypes(include=[np.number])\n",
    "# Check for missing values before correlation matrix\n",
    "#print(\"Missing values in numeric data:\")\n",
    "#print(numeric_data.isnull().sum())\n",
    "# Fill missing values\n",
    "numeric_data = numeric_data.fillna(numeric_data.mean())\n",
    "correlation_matrix = numeric_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Feature Selection: Check feature importance from RandomForest\n",
    "X = structured_data.drop(columns=['price'])\n",
    "y = structured_data['price']\n",
    "#rf_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "#rf_model.fit(X, y)\n",
    "#feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "#print(\"Feature Importances:\")\n",
    "#print(feature_importances)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model training and optimization\n",
    "rf_model = RandomForestRegressor()\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4)  # Reduced n_jobs to 4\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "#print(\"Optimized Random Forest MAE:\", mean_absolute_error(y_test, y_pred_best_rf))\n",
    "#print(\"Optimized Random Forest MSE:\", mean_squared_error(y_test, y_pred_best_rf))\n",
    "#print(\"Random Forest R-squared:\", r2_score(y_test, y_pred_best_rf))\n",
    "\n",
    "# Save the model and the encoders/scalers\n",
    "with open('best_rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_rf_model, f)\n",
    "\n",
    "with open('label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cardekho.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model and encoders/scalers\n",
    "with open('best_rf_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open('label_encoders.pkl', 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Function to safely encode categorical inputs\n",
    "def safe_transform(encoder, value):\n",
    "    if value in encoder.classes_:\n",
    "        return encoder.transform([value])[0]\n",
    "    else:\n",
    "        encoder.classes_ = np.append(encoder.classes_, value)\n",
    "        return encoder.transform([value])[0]\n",
    "\n",
    "# Map owner types to numeric values\n",
    "owner_type_mapping = {'First': 1, 'Second': 2, 'Third': 3, 'Fourth & Above': 4}\n",
    "\n",
    "# Streamlit app for prediction\n",
    "st.title(\"Used Car Price Predictor\")\n",
    "st.header(\"Enter the details of the car:\")\n",
    "\n",
    "\n",
    "# Input fields\n",
    "fuel_type = st.selectbox('Fuel Type', ['Petrol', 'Diesel', 'CNG', 'LPG', 'Electric'])\n",
    "body_type = st.selectbox('Body Type', ['Hatchback', 'Sedan', 'SUV', 'MPV', 'Convertible'])\n",
    "kilometers = st.number_input('Kilometers Driven', min_value=0)\n",
    "transmission = st.selectbox('Transmission', ['Manual', 'Automatic'])\n",
    "engine_capacity = st.number_input('Engine Capacity (cc)', min_value=0)\n",
    "make_year = st.number_input('Make Year', min_value=1950, max_value=2024)\n",
    "owner_type = st.selectbox('Owner Type', ['First', 'Second', 'Third', 'Fourth & Above'])\n",
    "city = st.selectbox('City', ['Delhi', 'Mumbai', 'Bangalore', 'Chennai', 'Hyderabad'])\n",
    "\n",
    "# Encode and scale input data using the encoders and scalers from the training phase\n",
    "input_data = pd.DataFrame({\n",
    "    'fuel_type': [safe_transform(label_encoders['fuel_type'], fuel_type)],\n",
    "    'body_type': [safe_transform(label_encoders['body_type'], body_type)],\n",
    "    'kilometers': [kilometers],\n",
    "    'transmission': [safe_transform(label_encoders['transmission'], transmission)],\n",
    "    'engine_capacity': [engine_capacity],\n",
    "    'make_year': [make_year],\n",
    "    'owner_type': [owner_type_mapping[owner_type]],\n",
    "    'City': [safe_transform(label_encoders['City'], city)]\n",
    "})\n",
    "\n",
    "# Create the log_kilometers feature\n",
    "#input_data['log_kilometers'] = np.log1p(input_data['kilometers'])\n",
    "\n",
    "# Normalize the numerical features\n",
    "input_data[['kilometers', 'engine_capacity']] = scaler.transform(input_data[['kilometers', 'engine_capacity']])\n",
    "\n",
    "# Make predictions\n",
    "if st.button(\"Predict Price\"):\n",
    "    prediction = model.predict(input_data)\n",
    "    st.success(f\"The estimated price of the car is: â‚¹{round(prediction[0], 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run cardekho.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vene",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
